#+NAME: cheetsheet
#+BEGIN_SRC bash

proxychains4 nix-env -f https://github.com/NixOS/nixpkgs/archive/master.tar.gz -iA haskell.packages.ghc844
#================
# REDHAT
#================
    cat /etc/sysconfig/network-scripts/ifcfg-eth0 
    DEVICE=eth0
    HWADDR=00:0C:29:D6:7C:73
    TYPE=Ethernet
    UUID=065d2da1-8409-48fc-a501-4fdf0ec57da9
    ONBOOT=yes
    NM_CONTROLLED=yes
    BOOTPROTO=static
    IPADDR=10.132.37.32
    NETMASK=255.255.255.0
    GATEWAY=10.132.37.254

    systemctl restart network

    yum groupinstall "KDE Plasma Workspaces" -y


#================
# UBUNTU
#================
    cat /etc/network/interfaces
    iface em1 inet static
    address 192.168.1.?
    netmask 255.255.0.0
    gateway 192.168.1.1

    sudo ifdown em1
    sudo ifup em1 

#================
# NixOS
#================
  wpa_passphrase 'hl03863' '@hl03863' > nix.conf/wpa_supplicant-2.6/hl03863.conf
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant-2.6/Shrbank.conf -iwlp7s0
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant-2.6/hl03863.conf -iwlp7s0
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant_YGY5G.conf -iwlp7s0
  
  #================
  # HYDRA
  #================
  export HYDRA_DBI="dbi:Pg:dbname=hydra;host=localhost;user=hydra;"
  export HYDRA_DATA=nix.var/data/hydra-2017-11-21/3000

  su root; su hydra
  hydra-create-user larluo --full-name 'larry.luo' --email-address 'larluo@clojurians.org' --password larluo --role admin

  ssh -i nix.sh.out/key root@192.168.56.101 "userdel -r op"

#================
# CLUSTER
#================
| SETUP
  ssh-copy-id -i nix.sh.out/key op@10.132.37.200
| KAFKA
  ssh op@10.132.37.34 'ps -ef | grep kafka-connect | grep -v grep | awk "{print \$2}" | xargs kill'
  cat my-tmp/data.txt | ~/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/kafka-console-producer --broker-list localhost:9092 --topic larluo
  CREATE STREAM larluo (_id VARCHAR, dt VARCHAR, type VARCHAR, id VARCHAR, count VARCHAR) WITH (KAFKA_TOPIC='larluo', VALUE_FORMAT='JSON')
  cat my-tmp/data.txt | ~/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/kafka-console-producer --broker-list localhost:9092 --topic larluo --property "parse.key=true" --property "key.separator=:"
  curl 10.132.37.201:8083/connectors/elasticsearch_sink_logi_pimp_protal/status | jq '.tasks[0].trace' | xargs echo -e

| KSQL
  SET 'auto.offset.reset' = 'earliest';
  SET 'auto.offset.reset' = 'latest' ;
  kafka-avro-console-producer \
    --property schema.registry.url=http://10.132.37.33:8081 \
    --broker-list 10.132.37.33:9092 --topic orders \
     --property value.schema='{"type":"record","name":"myrecord","fields":[{"name":"id","type":"int"},{"name":"product", "type": "string"}, {"name":"quantity", "type": "int"}, {"name":"price", "type": "float"}]}'

| ELK
  # elasticsearch [10.132.37.36:9200,10.132.37.37:9200,10.132.37.39:9200,10.132.37.40:9200]
  curl 10.132.37.36:9200/_cluster/health?pretty=true
  

#================
# VirtualBox
#================
  wget http://nixos.org/releases/nixos/virtualbox-nixops-images/virtualbox-nixops-18.03pre131587.b6ddb9913f2.vmdk.xz

  VBoxManage controlvm nixos-elk-001 poweroff
  VBoxManage controlvm nixos-elk-001 acpipowerbutton
  VBoxManage unregistervm --delete nixos-elk-001
  
  VBoxManage list runningvms
  VBoxManage list vms
  VBoxManage showvminfo --machinereadable nixos-elk-001

#================
# KSQL
#================

MY_CMD="EXPLAIN \
  SELECT EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.appID') AS app_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.mobileOS') AS mobile_os \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.mobileOSVersion') AS mobile_os_version \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.model') AS model \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.appVersion') AS app_version \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.crashTime') AS crash_time \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.openID') AS open_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.bundleID') AS bundle_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.errorStack') AS error_stack \
  FROM logi_hop_sdk_apm WHERE EXTRACTJSONFIELD(message, '\$.logger_name') = 'CrashInfoDev' ; "

curl -XPOST http://10.132.37.33:8088/ksql -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" -d "{\"ksql\": \"$MY_CMD\", \"streamsProperties\": {}}" | jq

#================
# CEPH
#================
ceph -s --conf ceph.conf --keyring ceph.client.admin.keyring

ceph-authtool --create-keyring ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'
ceph-authtool --create-keyring ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'
ceph-authtool ceph.mon.keyring --import-keyring ceph.client.admin.keyring
monmaptool --create --add nixos-larluo 10.129.132.112 --fsid 066ae264-2a5d-4729-8001-6ad265f50b03 monmap

ceph-mon --mkfs --cluster-name my_ceph -i nixos-larluo --monmap monmap --keyring ceph.mon.keyring --conf ceph.conf --mon-data ceph-mon/data -d
ceph-mon -f --cluster-name my_ceph --conf ceph.mon.conf --id nixos-larluo --setuser larluo --setgroup users --mon-data ceph-mon/data



ceph-authtool --create-keyring ceph.osd_10.129.132.112.keyring --name osd.10.129.132.112: --add-key AQBCEJNa3s8nHRAANvdsr93KqzBznuIWm2gOGg==
echo '{\"cephx_secret\": \"AQBCEJNa3s8nHRAANvdsr93KqzBznuIWm2gOGg==\"}' | ceph osd new 55ba2294-3e24-478f-bee0-9dca4c231dd9 -i -

ceph-osd --mkfs --cluster-name my_ceph -i 10.129.132.112_ --osd-uuid 55ba2294-3e24-478f-bee0-9dca4c231dd9
/nix/store/qkfb54nqqkliyb8f9ganibk9smj0jw8b-ceph-12.2.7/libexec/ceph/ceph-osd-prestart.sh --id ${daemonId} --cluster ${clusterName}
ceph-osd -f --conf ceph.osd.conf --id ods_10.129.132.112_port --setuser larluo --setgroup users --mon-data ceph-mon/ods/10.129.132.112   --osd-data ceph-mon/ods_10.129.132.112 --osd-journal PATH


#================
# DEPLOY
#================


#===============
# Exhibitor
#===============
bash nix.sh export exhibitor-1.5.6
/nix/store/w98dimrp5amhm9svaq5f1fnyx91mmyv1-exhibitor-1.5.6
startExhibitor.sh  --configtype zookeeper --zkconfigconnect localhost:2181 --zkconfigzpath /exhibitor/config --port 18080

hadoop daemonlog -setlevel 10.132.37.200:50075 org.apache.hadoop.hdfs.server.datanode.DataNode WARN

nix.var/data/hbase-1.2.6.1/hbase-1.2.6.1/bin/hbase --config . shell
hbase-site.xml
<configuration>
  <property>
   <name>hbase.cluster.distributed</name>
   <value>true</value>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
  <value>10.132.37.201:2181,10.132.37.202:2181,10.132.37.203:2181</value>
  </property>
  <!--
  <property>
    <name>zookeeper.znode.parent</name>
    <value>/hbase-unsecure</value>
  </property>
  -->
</configuration>

hdfs dfsadmin -fs 10.132.37.201:9000 -report
hdfs --loglevel DEBUG dfsadmin -fs hdfs://10.132.37.201:9000 -report
| `--loglevel loglevel` | Overrides the log level. Valid log levels are FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. Default is INFO. |


#===============
# CENTOS 7
#===============
mkdir -p ~/"VirtualBox VMs"/my-centos7
proxychains4 nix-env -i qemu
proxychains4 wget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
qemu-img convert -f qcow2 nix.sh.out/CentOS-7-x86_64-GenericCloud.qcow2 -O vdi ~/VirtualBox\ VMs/my-centos7/disk1.vdi

VBoxManage createvm --name "my-centos7" --ostype Linux26_64 --register
VBoxManage modifyvm "my-centos7" --memory 4096 --cpus 2 --vram 10 --nictype1 virtio --nictype2 virtio --nic2 hostonly --hostonlyadapter2 vboxnet0 --nestedpaging off --paravirtprovider kvm
VBoxManage startvm "my-centos7" --type headless

#============
# PROXY
#============
ssh -N -D 1080 git@10.132.37.56
curl -x socks5h://localhost:1080 www.baidu.com

#============
# PRESTO
#============
bash nix.sh start 10.132.37.200:5432 postgresql-10.7

nix-env -i libossp-uuid
wget -c -O /tmp/tgz.presto-server-309.d/presto-server-309.tar.gz https://repo1.maven.org/maven2/io/prestosql/presto-server/309/presto-server-309.tar.gz
cd /tmp/tgz.presto-server-309.d && tar -xvf presto-server-309.tar.gz && rm -rf presto-server-309.tar.gz && mv * tgz-presto-server-309
nix-store --add /tmp/tgz.presto-server-309.d/tgz-presto-server-309

nix-env -i /nix/store/fy1nf73pplslc23gix21rd0rmk825w2m-tgz-presto-server-309

./presto-cli-309-executable.jar --server localhost:4444 --catalog postgresql

nix-env -f '<nixpkgs>' -iA nodePackages.webpack

psql -h10.132.37.200 -Umonitor
nginx -c /home/op/my-env/nix.conf/nginx-1.15.12/nginx.conf

gitlab-rails console production
user = User.where(user:"op").first

#============ 
# NIXPKGS
#============
nix-env -f https://github.com/NixOS/nixpkgs/archive/19.03.tar.gz -qaP -A haskell.compiler
[ 19.03 18.09 18.03 17.09 17.03]

export NIX_PATH=nixpkgs=https://github.com/NixOS/nixpkgs/archive/18.09.tar.gz
nix-env -f '<nixpkgs>' -iA haskell.compiler.ghc802
nix-env -f '<nixpkgs>' -iA haskell.compiler.ghc7103

#================
# postgresql
#================
| gitit
stack build --nix --nix-packages "unzip zlib"
| postgrest
git clone https://github.com/PostgREST/postgrest.git
stack build --nix --nix-packages "postgresql zlib"
| postgres-websockets
git clone https://github.com/diogob/postgres-websockets
stack build --nix --nix-packages "postgresql zlib"


stack2nix . > default.nix
nix-build -A postgrest
nix-env -f '<nixpkgs>' -q --out-path postgrest-5.2.0 | awk  '{print $2}'

nix-build -A postgres-websockets

CREATE SERVER uat_demp FOREIGN DATA_WRAPPER oracle_fdw OPTIONS (dbserver "//X.X.X.X:1521/EDMP') ;
CREATE USER MAPPING FOR monitor SERVER uat_edmp OPTIONS (user 'KB', password 'XXXX') ;
CREATE FOREIGN TABLE tb_interface (
  ) SERVER uat_edmp OPTIONS (schema 'KB', table 'TB_INTERFACE') ;
#================
# HASKELL
#================
NIX_PATH=nixpkgs=https://github.com/NixOS/nixpkgs/archive/2c07921cff84dfb0b9e0f6c2d10ee2bfee6a85ac.tar.gz nix-build --no-out-link


#+END_SRC

