#+NAME: cheetsheet
#+BEGIN_SRC shell

proxychains4 nix-env -f https://github.com/NixOS/nixpkgs/archive/master.tar.gz -iA haskell.packages.ghc844
#================
# REDHAT
#================
    cat /etc/sysconfig/network-scripts/ifcfg-eth0 
    DEVICE=eth0
    HWADDR=00:0C:29:D6:7C:73
    TYPE=Ethernet
    UUID=065d2da1-8409-48fc-a501-4fdf0ec57da9
    ONBOOT=yes
    NM_CONTROLLED=yes
    BOOTPROTO=static
    IPADDR=10.132.37.32
    NETMASK=255.255.255.0
    GATEWAY=10.132.37.254

    systemctl restart network

    yum groupinstall "KDE Plasma Workspaces" -y


#================
# UBUNTU
#================
    cat /etc/network/interfaces
    iface em1 inet static
    address 192.168.1.?
    netmask 255.255.0.0
    gateway 192.168.1.1

    sudo ifdown em1
    sudo ifup em1 

#================
# NixOS
#================
  bash nix.sh export hello-2.10

  wpa_passphrase 'hl03863' '@hl03863' > nix.conf/wpa_supplicant-2.6/hl03863.conf
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant-2.6/Shrbank.conf -iwlp7s0
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant-2.6/hl03863.conf -iwlp7s0
  sudo wpa_supplicant -s -u -Dnl80211,wext -c nix.conf/wpa_supplicant_YGY5G.conf -iwlp7s0
  

  ss-local -s us1.wormholex.online -p 13173 -m chacha20-ietf -k ewxm9l -b 0.0.0.0 -l 1080 -v

  
  # rdkafka
  nix-prefetch-url --unpack --print-path https://github.com/edenhill/librdkafka/archive/v0.9.5.tar.gz
  nix-build -E 'with import <nixpkgs> {}; callPackage nixpkgs/rdkafka/default.nix {}'
  
  #================
  # HYDRA
  #================
  export HYDRA_DBI="dbi:Pg:dbname=hydra;host=localhost;user=hydra;"
  export HYDRA_DATA=nix.var/data/hydra-2017-11-21/3000

  su root; su hydra
  hydra-create-user larluo --full-name 'larry.luo' --email-address 'larluo@clojurians.org' --password larluo --role admin

  ssh -i nix.sh.out/key root@192.168.56.101 "userdel -r op"

#================
# KSQL
#================
  # zookeeper [10.132.37.33:2181,10.132.37.34:2181,10.132.37.35:2181]
  bash nix.sh export zookeeper-3.4.12
  bash nix.sh import 10.132.37.33 zookeeper-3.4.12
  bash nix.sh start-foreground 10.132.37.33:2181 zookeeper-3.4.12 --all "10.132.37.33:2181,10.132.37.34:2181,10.132.37.35:2181"

  echo ruok | nc 10.132.37.33 2181
  zkCli.sh -server "10.132.37.33:2181,10.132.37.34:2181,10.132.37.34:2181"

  # kafka [10.132.37.33:2181,10.132.37.34:2181,10.132.37.35:2181]
  bash nix.sh export apache-kafka-2.12-1.1.0 
  bash nix.sh import 10.132.37.33 apache-kafka-2.12-1.1.0
  bash nix.sh start-foreground 10.132.37.33:9092 apache-kafka-2.12-1.1.0 --zookeepers "10.132.37.33:2181,10.132.37.34:2181,10.132.37.35:2181" --cluster.id monitor

  kafka-topics.sh --zookeeper 10.132.37.33:2181/monitor --topic LOGI_CORES_PTS_EXT_AVRO --delete

  ssh op@10.132.37.34 'ps -ef | grep zookeeper | grep -v grep | awk "{print \$2}" | xargs kill'
  ssh op@10.132.37.33 "/home/op/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/ksql-server-stop"

  # kafka connect
  bash nix.sh start 10.132.37.33:8083 confluent-oss-5.0.0:kafka-connect --kafkas "10.132.37.33:9092,10.132.37.34:9092,10.132.37.35:9092" --cluster.id monitor
  ssh op@10.132.37.34 'ps -ef | grep ConnectDistributed | grep -v grep | awk "{print \$2}" | xargs kill'

  # ksql
  bash nix.sh start 10.132.37.33:8088 confluent-oss-5.0.0:ksql --kafkas 10.132.37.33:2181,10.132.37.34:2181,10.132.37.35:2181 --cluster.id monitor
  curl 10.132.37.34:8083
  ssh op@10.132.37.33 "/home/op/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/ksql-server-stop"


  ssh op@10.132.37.34 'ps -ef | grep kafka-connect | grep -v grep | awk "{print \$2}" | xargs kill'


#================
# ELK
#================

  # elasticsearch [10.132.37.36:9200,10.132.37.37:9200,10.132.37.39:9200,10.132.37.40:9200]
  curl 10.132.37.36:9200/_cluster/health?pretty=true
  
#================
# VirtualBox
#================
  wget http://nixos.org/releases/nixos/virtualbox-nixops-images/virtualbox-nixops-18.03pre131587.b6ddb9913f2.vmdk.xz

  VBoxManage controlvm nixos-elk-001 poweroff
  VBoxManage controlvm nixos-elk-001 acpipowerbutton
  VBoxManage unregistervm --delete nixos-elk-001
  
  VBoxManage list runningvms
  VBoxManage list vms
  VBoxManage showvminfo --machinereadable nixos-elk-001

#================
# KSQL
#================
  SET 'auto.offset.reset' = 'earliest';
  SET 'auto.offset.reset' = 'latest' ;

kafka-avro-console-producer \
 --property schema.registry.url=http://10.132.37.33:8081 \
 --broker-list 10.132.37.33:9092 --topic orders \
 --property value.schema='{"type":"record","name":"myrecord","fields":[{"name":"id","type":"int"},{"name":"product", "type": "string"}, {"name":"quantity", "type": "int"}, {"name":"price", "type": "float"}]}'


MY_CMD="EXPLAIN \
  SELECT EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.appID') AS app_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.mobileOS') AS mobile_os \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.mobileOSVersion') AS mobile_os_version \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.model') AS model \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.appVersion') AS app_version \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.crashTime') AS crash_time \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.openID') AS open_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.bundleID') AS bundle_id \
       , EXTRACTJSONFIELD(EXTRACTJSONFIELD(message, '\$.message'), '\$.errorStack') AS error_stack \
  FROM logi_hop_sdk_apm WHERE EXTRACTJSONFIELD(message, '\$.logger_name') = 'CrashInfoDev' ; "

curl -XPOST http://10.132.37.33:8088/ksql -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" -d "{\"ksql\": \"$MY_CMD\", \"streamsProperties\": {}}" | jq


#================
# Java
#================


http://www.jedi.be/blog/2011/11/04/vagrant-virtualbox-hostonly-pxe-vlans/


mkdir -p nix.opt/{tar.src,tar.bin,bin}

#================
# MIGRATE
#================
  bash nix.sh export tgz.nix-2.0.4
  bash nix.sh export nix.rsync-3.1.3
  bash nix.sh export nix.openjdk-8u172b11
  bash nix.sh export nix.leiningen-2.8.1
  bash nix.sh export nix.emacs-25.3

  bash nix.sh create-user 10.132.37.201
  bash nix.sh install 10.132.37.201 nix.rsync-3.1.3
  bash nix.sh install 10.132.37.201 nix.openjdk-8u172b11
  bash nix.sh install 10.132.37.201 tgz.nix-2.0.4
  bash nix.sh install 10.132.37.201 nix.leiningen-2.8.1
  bash nix.sh install 10.132.37.201 nix.emacs-25.3

cat my-tmp/data.txt | ~/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/kafka-console-producer --broker-list localhost:9092 --topic larluo
CREATE STREAM larluo (_id VARCHAR, dt VARCHAR, type VARCHAR, id VARCHAR, count VARCHAR) WITH (KAFKA_TOPIC='larluo', VALUE_FORMAT='JSON')
cat my-tmp/data.txt | ~/my-env/nix.var/data/confluent-oss-5.0.0/confluent-5.0.0/bin/kafka-console-producer --broker-list localhost:9092 --topic larluo --property "parse.key=true" --property "key.separator=:"


rsync --rsync-path=/home/op/.nix-profile/bin/rsync -av nix.sh.build/hbase-2.1.0/src.hbase-2.1.0.tgz  op@10.132.37.201:my-env/nix.sh.build/hbase-2.1.0/src.hbase-2.1.0.tgz
rsync --rsync-path=/home/op/.nix-profile/bin/rsync -av ~/.m2 op@10.132.37.201:~/.m2
https://hbase.apache.org/book.html#trouble.versions


http://10.132.37.36:9870

#================
# CEPH
#================
ceph -s --conf ceph.conf --keyring ceph.client.admin.keyring

ceph-authtool --create-keyring ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'
ceph-authtool --create-keyring ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'
ceph-authtool ceph.mon.keyring --import-keyring ceph.client.admin.keyring
monmaptool --create --add nixos-larluo 10.129.132.112 --fsid 066ae264-2a5d-4729-8001-6ad265f50b03 monmap

ceph-mon --mkfs --cluster-name my_ceph -i nixos-larluo --monmap monmap --keyring ceph.mon.keyring --conf ceph.conf --mon-data ceph-mon/data -d
ceph-mon -f --cluster-name my_ceph --conf ceph.mon.conf --id nixos-larluo --setuser larluo --setgroup users --mon-data ceph-mon/data



ceph-authtool --create-keyring ceph.osd_10.129.132.112.keyring --name osd.10.129.132.112: --add-key AQBCEJNa3s8nHRAANvdsr93KqzBznuIWm2gOGg==
echo '{\"cephx_secret\": \"AQBCEJNa3s8nHRAANvdsr93KqzBznuIWm2gOGg==\"}' | ceph osd new 55ba2294-3e24-478f-bee0-9dca4c231dd9 -i -

ceph-osd --mkfs --cluster-name my_ceph -i 10.129.132.112_ --osd-uuid 55ba2294-3e24-478f-bee0-9dca4c231dd9
/nix/store/qkfb54nqqkliyb8f9ganibk9smj0jw8b-ceph-12.2.7/libexec/ceph/ceph-osd-prestart.sh --id ${daemonId} --cluster ${clusterName}
ceph-osd -f --conf ceph.osd.conf --id ods_10.129.132.112_port --setuser larluo --setgroup users --mon-data ceph-mon/ods/10.129.132.112   --osd-data ceph-mon/ods_10.129.132.112 --osd-journal PATH



#================
# DEPLOY
#================
ssh-copy-id -i nix.sh.out/key op@10.132.37.200
ssh -i nix.sh.out/key op@10.132.37.200 "mkdir -p my-env/nix.sh.out"
scp -i nix.sh.out/key -r {nix.conf,nix.sh,nix.sh.dic,run.sh.d} op@10.132.37.200:my-env
scp -i nix.sh.out/key -r nix.sh.out/{tgz.nix-2.0.4,nix.rsync-3.1.3} op@10.132.37.200:my-env/nix.sh.out
ssh -i nix.sh.out/key op@10.132.37.200 bash nix.sh install 127.0.0.1 nix.rsync-3.1.3
rsync -av -e "ssh -i nix.sh.out/key" --info=progress2 --rsync-path=/home/op/.nix-profile/bin/rsync nix.sh.out op@10.132.37.200:my-env/nix.sh.out

curl 10.132.37.201:8083/connectors/elasticsearch_sink_logi_pimp_protal/status | jq '.tasks[0].trace' | xargs echo -e


#===============
# Exhibitor
#===============
bash nix.sh export exhibitor-1.5.6
/nix/store/w98dimrp5amhm9svaq5f1fnyx91mmyv1-exhibitor-1.5.6
startExhibitor.sh  --configtype zookeeper --zkconfigconnect localhost:2181 --zkconfigzpath /exhibitor/config --port 18080

hadoop daemonlog -setlevel 10.132.37.200:50075 org.apache.hadoop.hdfs.server.datanode.DataNode WARN

nix.var/data/hbase-1.2.6.1/hbase-1.2.6.1/bin/hbase --config . shell
hbase-site.xml
<configuration>
  <property>
   <name>hbase.cluster.distributed</name>
   <value>true</value>
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
  <value>10.132.37.201:2181,10.132.37.202:2181,10.132.37.203:2181</value>
  </property>
  <!--
  <property>
    <name>zookeeper.znode.parent</name>
    <value>/hbase-unsecure</value>
  </property>
  -->
</configuration>

hdfs dfsadmin -fs 10.132.37.201:9000 -report
hdfs --loglevel DEBUG dfsadmin -fs hdfs://10.132.37.201:9000 -report
| `--loglevel loglevel` | Overrides the log level. Valid log levels are FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. Default is INFO. |


#===============
# CENTOS 7
#===============
mkdir -p ~/"VirtualBox VMs"/my-centos7
proxychains4 nix-env -i qemu
proxychains4 wget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
qemu-img convert -f qcow2 nix.sh.out/CentOS-7-x86_64-GenericCloud.qcow2 -O vdi ~/VirtualBox\ VMs/my-centos7/disk1.vdi

VBoxManage createvm --name "my-centos7" --ostype Linux26_64 --register
VBoxManage modifyvm "my-centos7" --memory 4096 --cpus 2 --vram 10 --nictype1 virtio --nictype2 virtio --nic2 hostonly --hostonlyadapter2 vboxnet0 --nestedpaging off --paravirtprovider kvm
VBoxManage startvm "my-centos7" --type headless

#============
# PROXY
#============
ssh -N -D 1080 git@10.132.37.56
curl -x socks5h://localhost:1080 www.baidu.com

#============
# PRESTO
#============
bash nix.sh start 10.132.37.200:5432 postgresql-10.7

nix-env -i libossp-uuid
wget -c -O /tmp/tgz.presto-server-309.d/presto-server-309.tar.gz https://repo1.maven.org/maven2/io/prestosql/presto-server/309/presto-server-309.tar.gz
cd /tmp/tgz.presto-server-309.d && tar -xvf presto-server-309.tar.gz && rm -rf presto-server-309.tar.gz && mv * tgz-presto-server-309
nix-store --add /tmp/tgz.presto-server-309.d/tgz-presto-server-309

nix-env -i /nix/store/fy1nf73pplslc23gix21rd0rmk825w2m-tgz-presto-server-309

./presto-cli-309-executable.jar --server localhost:4444 --catalog postgresql

nix-env -f '<nixpkgs>' -iA nodePackages.webpack

psql -h10.132.37.200 -Umonitor

* gitlab-rails console production
* user = User.where(user:"op").first
```
#+ END_SRC
